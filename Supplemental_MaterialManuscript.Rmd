---
title: "Appendix"
output:
  pdf_document: default
  geometry: margin=1in
  documentclass: article
  word_document: default
  html_document:
    df_print: paged
---

\renewcommand{\thesection}{S\arabic{section}} 

\renewcommand{\thetable}{S\arabic{table}} 

\renewcommand{\thefigure}{S\arabic{figure}}

\setcounter{table}{0}

\setcounter{figure}{0}

\setcounter{section}{0}

\setcounter{page}{1}

# Supplemental Materials for: Assessing the Resistance and Resilience of Recreationally Important Fish Species to Extreme Events in Coastal Texas





```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = TRUE, warning = FALSE, message = FALSE)

## This will be a compilation of the supplementary material 

#Set working directory:
setwd("~/texas_extreme_events")

#Call in bag seines:
bag.seines <- read.csv("~/texas_extreme_events/Clean_TPWD_Data/UpdatedBagSeinesCondensed_CLEAN.csv")

#Packages:
library(tidyverse)
library(lubridate)
library(knitr)
options(digits = 4)
library(ggforce)
library(tidyverse)
library("hrbrthemes")
library(viridis)
library(forcats)
library(ggpubr)
library(kableExtra)
library(magick)
library(webshot2)
library(jtools)
library(huxtable)
library(xtable)
library(tibble)
library(lme4)
library(GGally)
library(performance)
library(broom)
library(broom.mixed)
library(MASS)


#color palette
colorBlindBlack8 <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00","#CC79A7")

#readable dates:
str(bag.seines)
bag.seines$DATE<- as.Date(bag.seines$DATE,
                                        format = "%m/%d/%y")

#adding the names of the bays into the data frame
bag.seines$MAJOR_AREA_CODE <- as.factor(bag.seines$MAJOR_AREA_CODE)

bag.seines <- bag.seines %>%  
  dplyr::mutate(MAJOR_AREA_CODE = recode(MAJOR_AREA_CODE, `1` = 'SabineLake', `2` = 'GalvestonBay', `3` = 'MatagordaBay', `4` = 'SanAntonioBay', `5`= 'AransasBay', `6`='CorpusChristiBay', `7`='UpperLagunaMadre', `8` = 'LowerLagunaMadre', `9`='EastMatagordaBay', `11` = 'CedarLakes'))

bag.seines <- bag.seines %>% 
  filter(!(MAJOR_AREA_CODE == "CedarLakes")) %>% 
  filter(!(MAJOR_AREA_CODE == "EastMatagordaBay"))

##Plot
My_Theme <- theme(
  axis.title.x = element_text(size = 12),
  axis.text.x = element_text(size = 12),
  axis.title.y = element_text(size = 12),
  plot.title = element_text(size = 12),
  legend.text = element_text(size = 12),
  legend.title = element_text(size = 12),
  axis.ticks.length = unit(0.20, "cm"),
  axis.text.y = element_text(size = 12))



```

```{r time series Monthly Analysis Calculations, include=FALSE}
#calculate monthly averages:
#adding the names of the bays into the data frame
bag.seines$MAJOR_AREA_CODE <- as.factor(bag.seines$MAJOR_AREA_CODE)

#bag.seines <- bag.seines %>% 
  #filter(!(MAJOR_AREA_CODE == "CedarLakes")) %>% 
  #filter(!(MAJOR_AREA_CODE == "EastMatagordaBay"))

## Red drum Monthly Average Calculations -----
redDrum_mon_avg <- bag.seines %>%
  group_by(MONTH,YEAR,MAJOR_AREA_CODE) %>%
  summarize(mean(rd_CPUE))

redDrum_mon_avg <- redDrum_mon_avg %>%
  rename("CPUE_AvgRD" = "mean(rd_CPUE)")


# making column that combines month and year
redDrum_mon_avg$DAY <- 1
redDrum_mon_avg$MDY <- paste(redDrum_mon_avg$MONTH,redDrum_mon_avg$DAY, redDrum_mon_avg$YEAR, sep = "-")
redDrum_mon_avg$MDY <- as.Date(redDrum_mon_avg$MDY, format = "%m-%d-%Y")


## Spotted seatrout Calculation ------
sst_mon_avg <- bag.seines %>%
  group_by(MONTH,YEAR,MAJOR_AREA_CODE) %>%
  summarize(mean(sst_CPUE))

sst_mon_avg <- sst_mon_avg %>%
  rename("CPUE_AvgSST" = "mean(sst_CPUE)")

#sst_mon_avg$MAJOR_AREA_CODE <- as.character(sst_mon_avg$MAJOR_AREA_CODE)

#creating a data column for easier interpretation 
sst_mon_avg$DAY <- 1
sst_mon_avg$MDY <- paste(sst_mon_avg$MONTH,sst_mon_avg$DAY, sst_mon_avg$YEAR, sep = "-")
sst_mon_avg$MDY <- as.Date(sst_mon_avg$MDY, format = "%m-%d-%Y")



#Black drum calculation ---- 
blackDrum_mon_avg <- bag.seines %>%
  group_by(MONTH,YEAR,MAJOR_AREA_CODE) %>%
  summarize(mean(bd_CPUE))

blackDrum_mon_avg  <- blackDrum_mon_avg  %>%
  rename("CPUE_AvgBD" = "mean(bd_CPUE)")

blackDrum_mon_avg$MAJOR_AREA_CODE <- as.character(blackDrum_mon_avg$MAJOR_AREA_CODE)

## creating a data column
blackDrum_mon_avg$DAY <- 1
blackDrum_mon_avg$MDY <- paste(blackDrum_mon_avg$MONTH,blackDrum_mon_avg$DAY, blackDrum_mon_avg$YEAR, sep = "-")
blackDrum_mon_avg$MDY <- as.Date(blackDrum_mon_avg$MDY, format = "%m-%d-%Y")


## Southern Flounder calculation ----

SF_mon_avg <- bag.seines %>%
  group_by(MONTH,YEAR,MAJOR_AREA_CODE) %>%
  summarize(mean(sf_CPUE))

SF_mon_avg  <- SF_mon_avg %>%
  rename("CPUE_AvgSF" = "mean(sf_CPUE)")

SF_mon_avg$MAJOR_AREA_CODE <- as.character(SF_mon_avg$MAJOR_AREA_CODE)

#Creating a data column for easier plot interpretation
SF_mon_avg$DAY <- 1
SF_mon_avg$MDY <- paste(SF_mon_avg$MONTH,SF_mon_avg$DAY, SF_mon_avg$YEAR, sep = "-")
SF_mon_avg$MDY <- as.Date(SF_mon_avg$MDY, format = "%m-%d-%Y")




```


# Time series analysis plots 



```{r Red drum time series plots, parsed out by bay , echo=FALSE, fig.cap= "Red Drum monthly averaged CPUE over the last ten years parsed out by bay system. Dotted lines signifing two extreme events, Hurricane Harvey and the 2021 Texas Freeze, left to right."}

## red drum plot
ggplot(data = redDrum_mon_avg %>% filter(YEAR > 2012), mapping = aes(x = MDY, y =  CPUE_AvgRD)) + geom_line(alpha = 0.8, size = 1) +  
geom_vline(xintercept = as.numeric(as.Date("2017-08-01")), linetype=4, size = 1, color = "#000000") + 
geom_vline(xintercept = as.numeric(as.Date("2021-02-01")), linetype=4, size=1, color = "#000000") +
theme_classic() + facet_wrap(~MAJOR_AREA_CODE, scales = "free") +
   scale_x_date(date_labels = "%Y", date_breaks = "1 year") +
  labs(
  title = "Red Drum CPUE Monthly Average Since 2013",
  x = "Time",
  y = "CPUE (#/hectare)" 
) + theme(axis.text.x = element_text(angle=45, hjust=1))


```

```{r spotted seatrout time series plots, parsed out by bay , echo=FALSE, fig.cap= "Spotted Seatrout monthly averaged CPUE over the last ten years parsed out by bay system. Dotted lines signifing two extreme events, Hurricane Harvey and the 2021 Texas Freeze, left to right."}

#spotted seatrout plot
ggplot(data = sst_mon_avg %>% filter(YEAR > 2012), mapping = aes(x = MDY, y =  CPUE_AvgSST)) + geom_line(alpha = 0.8, size = 1) + theme_classic() + facet_wrap(~MAJOR_AREA_CODE, scale = "free") +  
  geom_vline(xintercept = as.numeric(as.Date("2017-08-01")), linetype=4, size = 1, color = "#000000")+
  geom_vline(xintercept = as.numeric(as.Date("2021-02-01")), linetype=4, size = 1, color = "#000000") +
  scale_x_date(date_labels = "%Y", date_breaks = "1 year") +
  labs(
    title = "Spotted Seatrout CPUE Monthly Average since 2013",
    x = "Time",
    y = "CPUE (#/hectare)"
  )+ theme(axis.text.x = element_text(angle=45, hjust=1)) 
```


```{r black drum time series plots, parsed out by bay , echo=FALSE, fig.cap= "Black Drum monthly averaged CPUE over the last ten years parsed out by bay system. Dotted lines signifing two extreme events, Hurricane Harvey and the 2021 Texas Freeze, left to right."}
## black drum plot
ggplot(data = blackDrum_mon_avg  %>% filter(YEAR > 2012), mapping = aes(x = MDY, y =  CPUE_AvgBD)) + geom_line(alpha = 0.8, size = 1) + theme_classic() + facet_wrap(~MAJOR_AREA_CODE, scale = "free") +  
  geom_vline(xintercept = as.numeric(as.Date("2017-08-01")), linetype=4, size = 1, color = "#000000")+
  geom_vline(xintercept = as.numeric(as.Date("2021-02-01")), linetype=4, size = 1, color = "#000000") +
  scale_x_date(date_labels = "%Y", date_breaks = "1 year") +
 labs(
  title = "Black Drum CPUE Monthly Average since 2013",
  x = "Time",
  y = "CPUE (#/hectare)"
) + theme(axis.text.x = element_text(angle=45, hjust=1))

```


```{r Southern Flounder time series plots, parsed out by bay , echo=FALSE, fig.cap= "Southern Flounder monthly averaged CPUE over the last ten years parsed out by bay system. Dotted lines signifing two extreme events, Hurricane Harvey and the 2021 Texas Freeze, left to right."}
## southern flounder plot
ggplot(data = SF_mon_avg %>% filter(YEAR > 2012), mapping = aes(x = MDY, y =  CPUE_AvgSF)) + geom_line(alpha = 0.8, size = 1) + theme_classic() + facet_wrap(~MAJOR_AREA_CODE, scale = "free") +  
  geom_vline(xintercept = as.numeric(as.Date("2017-08-01")), linetype=4, size = 1, color = "#000000")+
  geom_vline(xintercept = as.numeric(as.Date("2021-02-01")), linetype=4, size = 1, color = "#000000") +
  scale_x_date(date_labels = "%Y", date_breaks = "1 year") +
  labs(
  title = "Southern Flounder CPUE Monthly Average since 2013",
  x = "Time",
  y = "CPUE (#/hectare)"
) + theme(axis.text.x = element_text(angle=45, hjust=1))

```

\newpage

# Recruitment Windows

```{r red drum recruitment window, fig.cap= "Red Drum CPUE monthly average raw data points plots over julian day establishing the recruitment window for Red Drum." }
###Plotting the raw data points starts here####
#plot
ggplot(data = bag.seines %>% filter(YEAR > 2012 & YEAR < 2024), mapping = aes(x = as.Date(JULIAN_DATE, origin = as.Date("2021-01-01")), y = rd_CPUE, group=as.factor(YEAR), color = as.factor(YEAR))) + geom_point() + #geom_smooth() +
  theme_classic() + #facet_wrap(~MAJOR_AREA_CODE) +
  scale_x_date(date_labels = "%b", date_breaks = "1 month") +
  labs(
    title = "Red Drum CPUE Monthly Average Since 2013",
    x = "Time",
    y = "CPUE (#/hectare)",
    color = "Year"
  )

```

```{r SST recruitment window, fig.cap= "Spotted Seatrout CPUE monthly average raw data points plots over julian day establishing the recruitment window for Spotted Seatrout." }

ggplot(data = bag.seines %>% filter(YEAR > 2012 & YEAR < 2024), mapping = aes(x = as.Date(JULIAN_DATE, origin = as.Date("2021-01-01")), y = (sst_CPUE), group=as.factor(YEAR), color = as.factor(YEAR))) + geom_point() + #geom_smooth() +
  theme_classic() + #facet_wrap(~MAJOR_AREA_CODE) +
  scale_x_date(date_labels = "%b", date_breaks = "1 month") +
  labs(
    title = "SST CPUE Monthly Average Since 2013",
    x = "Time",
    y = "CPUE (#/hectare)",
     color = "Year"
  )
```


```{r Black Drum recruitment window, fig.cap= "Black Drum CPUE monthly average raw data points plots over julian day establishing the recruitment window for Black Drum."}

ggplot(data = bag.seines %>% filter(YEAR > 2012 & YEAR < 2024), mapping = aes(x = as.Date(JULIAN_DATE, origin = as.Date("2021-01-01")), y = bd_CPUE, group=as.factor(YEAR), color = as.factor(YEAR))) + geom_point() + #geom_smooth() +
  theme_classic() + #facet_wrap(~MAJOR_AREA_CODE) +
  scale_x_date(date_labels = "%b", date_breaks = "1 month") +
  labs(
    title = "Black Drum CPUE Monthly Average Since 2013",
    x = "Time",
    y = "CPUE (#/hectare)",
     color = "Year"
  ) + ylim(0,4000)


```

```{r SF recruitment window, fig.cap= "Southern Flounder CPUE monthly average raw data points plots over julian day establishing the recruitment window for Southern Flounder."}

ggplot(data = bag.seines %>% filter(YEAR > 2012 & YEAR < 2024), mapping = aes(x = as.Date(JULIAN_DATE, origin = as.Date("2021-01-01")), y = sf_CPUE, group=as.factor(YEAR), color = as.factor(YEAR))) + geom_point() + #geom_smooth() +
  theme_classic() + #facet_wrap(~MAJOR_AREA_CODE) +
  scale_x_date(date_labels = "%b", date_breaks = "1 month") +
  labs(
    title = "Southern Flounder CPUE Monthly Average Since 2013",
    x = "Time",
    y = "CPUE (#/hectare)",
     color = "Year"
  )


```

\newpage


# Hurricane Harvey Percent Change Tables

```{r Red Drum Hurricane}
#I had to first subset into the 10 year frame I wanted (no averaging)
check2 <- bag.seines %>%
  filter(YEAR > 2006 & YEAR < 2018 ) %>% 
  group_by(MAJOR_AREA_CODE)

#Then I had to subset for only the months I wanted for red drum (oct - end of may)
check3 <- check2 %>% 
  filter(MONTH < 6 ) %>% 
  group_by(MAJOR_AREA_CODE)

check4 <- check2 %>% 
  filter(MONTH > 9) %>% 
  group_by(MAJOR_AREA_CODE)
#pasting them together
finalcheck <- rbind(check3, check4)

## I realized that the data set has data from an incomplete recruitment window since it starts with 2007 in jan (this recruitment window would have started in oct of the previous year) so I need to make sure it starts in oct of 2007 and ends may of 2016 for the averages
 
finalcheck <- finalcheck %>% 
  filter(DATE > "2007-09-30") %>% 
  filter(DATE < "2017-06-01")


#ggplot(finalcheck, mapping = aes(x=JULIAN_DATE, y = rd_CPUE)) + geom_point() + theme_classic()

#Final step = Averaging for the baseline
RE.RD10yr.hurricane <- finalcheck %>% 
  group_by(MAJOR_AREA_CODE) %>% 
  summarize(mean(rd_CPUE)) %>% 
  rename("CPUE" = "mean(rd_CPUE)")

RE.RD10yr.hurricane$SPECIES <- "Red Drum"
RE.RD10yr.hurricane$AVERAGE <- "10 yrs"

## post storm calculations = 2 post storm recruitment windows
RE.RD1yr.hurricane <- bag.seines %>%
  filter(between(DATE, as.Date('2017-10-01'), as.Date('2018-05-31'))) %>% 
  group_by(MAJOR_AREA_CODE) %>%
  summarize(mean(rd_CPUE)) %>%
  rename("CPUE" = "mean(rd_CPUE)")

RE.RD1yr.hurricane$SPECIES <- "Red Drum"
RE.RD1yr.hurricane$AVERAGE <- "1st year"


RE.RD2nd.hurricane <- bag.seines %>%
  filter(between(DATE, as.Date('2018-10-01'), as.Date('2019-05-31'))) %>% 
  group_by(MAJOR_AREA_CODE) %>%
  summarize(mean(rd_CPUE)) %>%
  rename("CPUE" = "mean(rd_CPUE)")

RE.RD2nd.hurricane$SPECIES <- "Red Drum"
RE.RD2nd.hurricane$AVERAGE <- "2nd year"

RE.RDbyyear.Hurr <- rbind(RE.RD10yr.hurricane,RE.RD1yr.hurricane,RE.RD2nd.hurricane)


#Plotting
#ggplot(data = RE.RDbyyear.Hurr , mapping = aes(x = MAJOR_AREA_CODE, y =  CPUE, fill = AVERAGE)) +  geom_bar(stat="identity", color="black", position=position_dodge()) + scale_fill_grey() + theme_classic() + labs(
  #title = "10 yr avg vs post storm avg for RD across bays using NEW baselines",
  #x = "Major bays",
 # y = "Catch per Unit Effort (#/hectare)"
#) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


## PERCENT CHANGES
#make it wide:
RE.RD.Spread.PerChange <- spread(RE.RDbyyear.Hurr, AVERAGE, CPUE)

## Add the column to put in the percent change values
RE.RD.Spread.PerChange$first_perChange <- NA
RE.RD.Spread.PerChange$second_perChange <- NA

# for loop calculating per change for the first year
for (i in 1:nrow(RE.RD.Spread.PerChange)){
  RE.RD.Spread.PerChange$first_perChange[i] = format(((RE.RD.Spread.PerChange$`1st year`[i] - RE.RD.Spread.PerChange$`10 yrs`[i]) /RE.RD.Spread.PerChange$`10 yrs`[i]) * 100 , scientific = F)
}

#for loop for calculating per change for the 2nd year to the baseline = 
for (i in 1:nrow(RE.RD.Spread.PerChange)){
  RE.RD.Spread.PerChange$second_perChange[i] = format(((RE.RD.Spread.PerChange$`2nd year`[i] - RE.RD.Spread.PerChange$`10 yrs`[i]) /RE.RD.Spread.PerChange$`10 yrs`[i]) * 100 , scientific = F)
}
```


```{r HH Red Drum Percent Change Table}

#table <- RE.RD.Spread.PerChange
#table <- table %>%  rename(
 #"Bays" = "MAJOR_AREA_CODE"
#)

kable(RE.RD.Spread.PerChange, "latex", booktabs = T, caption = "Red Drum percent changes after Hurricane Harvey") %>% 
  kable_styling(latex_options = c("HOLD_position","scale_down"), full_width = F)

```

```{r Spotted Seatrout Hurricane}
#I had to first subset into the 10 year frame I wanted (no averaging)
subset5 <- bag.seines %>%
  filter(YEAR > 2006 & YEAR < 2017 ) %>% 
  group_by(MAJOR_AREA_CODE)

#Then I had to subset for only the months I wanted for spotted seatrout (june - end of december)
subset6 <- subset5 %>% 
  filter(MONTH > 5 ) %>% 
  group_by(MAJOR_AREA_CODE)

#ggplot(subset6, mapping = aes(x=JULIAN_DATE, y = sst_CPUE)) + geom_point() + theme_classic()

#Final step = Averaging for the baseline
RE.SST10yr.hurricane <- subset6 %>% 
  group_by(MAJOR_AREA_CODE) %>% 
  summarize(mean(sst_CPUE)) %>% 
  rename("CPUE" = "mean(sst_CPUE)")

RE.SST10yr.hurricane$SPECIES <- "Spotted Seatrout"
RE.SST10yr.hurricane$AVERAGE <- "10 yrs"

## post storm calculations = 2 post storm recruitment windows
RE.SST1yr.hurricane <- bag.seines %>%
  filter(between(DATE, as.Date('2018-06-01'), as.Date('2018-12-31'))) %>% 
  group_by(MAJOR_AREA_CODE) %>%
  summarize(mean(sst_CPUE)) %>%
  rename("CPUE" = "mean(sst_CPUE)")

RE.SST1yr.hurricane$SPECIES <- "Spotted Seatrout"
RE.SST1yr.hurricane$AVERAGE <- "1st year"


RE.SST2nd.hurricane <- bag.seines %>%
  filter(between(DATE, as.Date('2019-06-01'), as.Date('2019-12-31'))) %>% 
  group_by(MAJOR_AREA_CODE) %>%
  summarize(mean(sst_CPUE)) %>%
  rename("CPUE" = "mean(sst_CPUE)")

RE.SST2nd.hurricane$SPECIES <- "Spotted Seatrout"
RE.SST2nd.hurricane$AVERAGE <- "2nd year"

RE.SSTbyyear.Hurr <- rbind(RE.SST10yr.hurricane,RE.SST1yr.hurricane,RE.SST2nd.hurricane)


#Plotting
#ggplot(data = RE.SSTbyyear.Hurr , mapping = aes(x = MAJOR_AREA_CODE, y =  CPUE, fill = AVERAGE)) +  geom_bar(stat="identity", color="black", position=position_dodge()) + scale_fill_grey() + theme_classic() + labs(
  #title = "10 yr avg vs post storm avg for SST across bays using NEW baselines",
  #x = "Major bays",
  #y = "Catch per Unit Effort (#/hectare)"
#) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

## PERCENT CHANGES
#make it wide:
RE.SST.Spread.PerChange <- spread(RE.SSTbyyear.Hurr, AVERAGE, CPUE)

## Add the column to put in the percent change values
RE.SST.Spread.PerChange$first_perChange <- NA
RE.SST.Spread.PerChange$second_perChange <- NA

# for loop calculating per change for the first year
for (i in 1:nrow(RE.SST.Spread.PerChange)){
  RE.SST.Spread.PerChange$first_perChange[i] = format(((RE.SST.Spread.PerChange$`1st year`[i] - RE.SST.Spread.PerChange$`10 yrs`[i]) /RE.SST.Spread.PerChange$`10 yrs`[i]) * 100 , scientific = F)
}

#for loop for calculating per change for the 2nd year to the baseline = 
for (i in 1:nrow(RE.SST.Spread.PerChange)){
  RE.SST.Spread.PerChange$second_perChange[i] = format(((RE.SST.Spread.PerChange$`2nd year`[i] - RE.SST.Spread.PerChange$`10 yrs`[i]) /RE.SST.Spread.PerChange$`10 yrs`[i]) * 100 , scientific = F)
}

```

```{r HH and Spotted Seatrout Table}

kable(RE.SST.Spread.PerChange, "latex", booktabs = T, caption = "Spotted Seatrout percent changes after Hurricane Harvey") %>% 
  kable_styling(latex_options = c("HOLD_position","scale_down"), full_width = F)

```

```{r Black Drum and Hurricane}
## Recruitment window is April to end of oct 
#I had to first subset into the 10 year frame I wanted (no averaging)
subset9 <- bag.seines %>%
  filter(YEAR > 2006 & YEAR < 2017 ) %>% 
  group_by(MAJOR_AREA_CODE)


#Then I had to subset for only the months I wanted for black drum (April to end of oct)
subset10 <- subset9 %>% 
  filter(MONTH > 3 & MONTH < 11 ) %>% 
  group_by(MAJOR_AREA_CODE)

#ggplot(subset10, mapping = aes(x=JULIAN_DATE, y = bd_CPUE)) + geom_point() + theme_classic()

#Final step = Averaging for the baseline
RE.BD10yr.hurricane <- subset10 %>% 
  group_by(MAJOR_AREA_CODE) %>% 
  summarize(mean(bd_CPUE)) %>% 
  rename("CPUE" = "mean(bd_CPUE)")

RE.BD10yr.hurricane$SPECIES <- "Black Drum"
RE.BD10yr.hurricane$AVERAGE <- "10 yrs"

## post storm calculations = 2 post storm recruitment windows
RE.BD1yr.hurricane <- bag.seines %>%
  filter(between(DATE, as.Date('2018-04-01'), as.Date('2018-10-31'))) %>% 
  group_by(MAJOR_AREA_CODE) %>%
  summarize(mean(bd_CPUE)) %>%
  rename("CPUE" = "mean(bd_CPUE)")

RE.BD1yr.hurricane$SPECIES <- "Black Drum"
RE.BD1yr.hurricane$AVERAGE <- "1st year"


RE.BD2nd.hurricane <- bag.seines %>%
  filter(between(DATE, as.Date('2019-04-01'), as.Date('2019-10-31'))) %>% 
  group_by(MAJOR_AREA_CODE) %>%
  summarize(mean(bd_CPUE)) %>%
  rename("CPUE" = "mean(bd_CPUE)")

RE.BD2nd.hurricane$SPECIES <- "Black Drum"
RE.BD2nd.hurricane$AVERAGE <- "2nd year"

RE.BDbyyear.Hurr <- rbind(RE.BD10yr.hurricane,RE.BD1yr.hurricane,RE.BD2nd.hurricane)


#Plotting
#ggplot(data = RE.BDbyyear.Hurr , mapping = aes(x = MAJOR_AREA_CODE, y =  CPUE, fill = AVERAGE)) +  geom_bar(stat="identity", color="black", position=position_dodge()) + scale_fill_grey() + theme_classic() + labs(
  #title = "10 yr avg vs post storm avg for BD across bays using NEW baselines",
  #x = "Major bays",
  #y = "Catch per Unit Effort (#/hectare)"
#) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

## PERCENT CHANGES
#make it wide:
RE.BD.Spread.PerChange <- spread(RE.BDbyyear.Hurr, AVERAGE, CPUE)

## Add the column to put in the percent change values
RE.BD.Spread.PerChange$first_perChange <- NA
RE.BD.Spread.PerChange$second_perChange <- NA

# for loop calculating per change for the first year
for (i in 1:nrow(RE.BD.Spread.PerChange)){
  RE.BD.Spread.PerChange$first_perChange[i] = format(((RE.BD.Spread.PerChange$`1st year`[i] - RE.BD.Spread.PerChange$`10 yrs`[i]) /RE.BD.Spread.PerChange$`10 yrs`[i]) * 100 , scientific = F)
}

#for loop for calculating per change for the 2nd year to the baseline = 
for (i in 1:nrow(RE.BD.Spread.PerChange)){
  RE.BD.Spread.PerChange$second_perChange[i] = format(((RE.BD.Spread.PerChange$`2nd year`[i] - RE.BD.Spread.PerChange$`10 yrs`[i]) /RE.BD.Spread.PerChange$`10 yrs`[i]) * 100 , scientific = F)
}

```

```{r HH Black Drum Table}
kable(RE.BD.Spread.PerChange, "latex", booktabs = T, caption = "Black Drum percent changes after Hurricane Harvey") %>% 
  kable_styling(latex_options = c("HOLD_position","scale_down"), full_width = F)

```

```{r Southern Flounder and Hurricane}
## Recruitment window is feb to end of july

#I had to first subset into the 10 year frame I wanted (no averaging)
subset13 <- bag.seines %>%
  filter(YEAR > 2006 & YEAR < 2017 ) %>% 
  group_by(MAJOR_AREA_CODE)


#Then I had to subset for only the months I wanted for southern flounder (feb - end of july)
subset14 <- subset13 %>% 
  filter(MONTH > 1 & MONTH < 8 ) %>% 
  group_by(MAJOR_AREA_CODE)

#ggplot(subset14, mapping = aes(x=JULIAN_DATE, y = sf_CPUE)) + geom_point() + theme_classic()

#Final step = Averaging for the baseline
RE.SF10yr.hurricane <- subset14 %>% 
  group_by(MAJOR_AREA_CODE) %>% 
  summarize(mean(sf_CPUE)) %>% 
  rename("CPUE" = "mean(sf_CPUE)")

RE.SF10yr.hurricane$SPECIES <- "Southern Flounder"
RE.SF10yr.hurricane$AVERAGE <- "10 yrs"

## post storm calculations = 2 post storm recruitment windows
RE.SF1yr.hurricane <- bag.seines %>%
  filter(between(DATE, as.Date('2018-02-01'), as.Date('2018-07-31'))) %>% 
  group_by(MAJOR_AREA_CODE) %>%
  summarize(mean(sf_CPUE)) %>%
  rename("CPUE" = "mean(sf_CPUE)")

RE.SF1yr.hurricane$SPECIES <- "Southern Flounder"
RE.SF1yr.hurricane$AVERAGE <- "1st year"


RE.SF2nd.hurricane <- bag.seines %>%
  filter(between(DATE, as.Date('2019-02-01'), as.Date('2019-07-31'))) %>% 
  group_by(MAJOR_AREA_CODE) %>%
  summarize(mean(sf_CPUE)) %>%
  rename("CPUE" = "mean(sf_CPUE)")

RE.SF2nd.hurricane$SPECIES <- "Southern Flounder"
RE.SF2nd.hurricane$AVERAGE <- "2nd year"

RE.SFbyyear.Hurr <- rbind(RE.SF10yr.hurricane,RE.SF1yr.hurricane,RE.SF2nd.hurricane)


#Plotting
#ggplot(data = RE.SFbyyear.Hurr , mapping = aes(x = MAJOR_AREA_CODE, y =  CPUE, fill = AVERAGE)) +  geom_bar(stat="identity", color="black", position=position_dodge()) + scale_fill_grey() + theme_classic() + labs(
 # title = "10 yr avg vs post storm avg for SF across bays using NEW baselines",
 # x = "Major bays",
  #y = "Catch per Unit Effort (#/hectare)"
#) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

## PERCENT CHANGES
#make it wide:
RE.SF.Spread.PerChange <- spread(RE.SFbyyear.Hurr, AVERAGE, CPUE)

## Add the column to put in the percent change values
RE.SF.Spread.PerChange$first_perChange <- NA
RE.SF.Spread.PerChange$second_perChange <- NA

# for loop calculating per change for the first year
for (i in 1:nrow(RE.SF.Spread.PerChange)){
  RE.SF.Spread.PerChange$first_perChange[i] = format(((RE.SF.Spread.PerChange$`1st year`[i] - RE.SF.Spread.PerChange$`10 yrs`[i]) /RE.SF.Spread.PerChange$`10 yrs`[i]) * 100 , scientific = F)
}

#for loop for calculating per change for the 2nd year to the baseline = 
for (i in 1:nrow(RE.SF.Spread.PerChange)){
  RE.SF.Spread.PerChange$second_perChange[i] = format(((RE.SF.Spread.PerChange$`2nd year`[i] - RE.SF.Spread.PerChange$`10 yrs`[i]) /RE.SF.Spread.PerChange$`10 yrs`[i]) * 100 , scientific = F)
}

```

```{r HH and Southern Flounder Table, }
kable(RE.SF.Spread.PerChange, "latex", booktabs = T, caption = "Southern Flounder percent changes after Hurricane Harvey") %>% 
  kable_styling(latex_options = c("HOLD_position","scale_down"), full_width = F)
```

\newpage

# Texas 2021 Freeze Percent Change Tables 
```{r Red Drum Feeze}

#I had to first subset into the 10 year frame I wanted (no averaging)
subset2 <- bag.seines %>%
  filter(YEAR > 2008 & YEAR < 2020 ) %>% 
  group_by(MAJOR_AREA_CODE)
#summarize(mean(rd_CPUE)) %>%
#rename("CPUE" = "mean(rd_CPUE)")

#Then I had to subset for only the months I wanted for red drum (oct - end of may)
subset3 <- subset2 %>% 
  filter(MONTH < 6 ) %>% 
  group_by(MAJOR_AREA_CODE)

subset4 <- subset2 %>% 
  filter(MONTH > 9) %>% 
  group_by(MAJOR_AREA_CODE)
#pasting them together
finalsubset <- rbind(subset3, subset4)

## I realized that the data set has data from an incomplete recruitment window since it starts with 2009 in jan (this recruitment window would have started in oct of the previous year) so I need to make sure it starts in oct of 2009 and ends may of 2019 for the averages

finalsubset <- finalsubset %>% 
  filter(DATE > "2009-09-30") %>% 
  filter(DATE < "2019-06-01")


#ggplot(finalsubset, mapping = aes(x=JULIAN_DATE, y = rd_CPUE)) + geom_point() + theme_classic()

#Final step = Averaging for the baseline
RE.RD10yr.freeze <- finalsubset %>% 
  group_by(MAJOR_AREA_CODE) %>% 
  summarize(mean(rd_CPUE)) %>% 
  rename("CPUE" = "mean(rd_CPUE)")

RE.RD10yr.freeze$SPECIES <- "Red Drum"
RE.RD10yr.freeze$AVERAGE <- "10 yrs"

## post storm calculations = 2 post storm recruitment windows
RE.RD1yr.freeze <- bag.seines %>%
  filter(between(DATE, as.Date('2021-10-01'), as.Date('2022-05-31'))) %>% 
  group_by(MAJOR_AREA_CODE) %>%
  summarize(mean(rd_CPUE)) %>%
  rename("CPUE" = "mean(rd_CPUE)")

RE.RD1yr.freeze$SPECIES <- "Red Drum"
RE.RD1yr.freeze$AVERAGE <- "1st year"


RE.RD2nd.freeze<- bag.seines %>%
  filter(between(DATE, as.Date('2022-10-01'), as.Date('2023-05-31'))) %>% 
  group_by(MAJOR_AREA_CODE) %>%
  summarize(mean(rd_CPUE)) %>%
  rename("CPUE" = "mean(rd_CPUE)")

RE.RD2nd.freeze$SPECIES <- "Red Drum"
RE.RD2nd.freeze$AVERAGE <- "2nd year"

RE.RDbyyear.Freeze <- rbind(RE.RD10yr.freeze,RE.RD1yr.freeze,RE.RD2nd.freeze)


#Plotting
#ggplot(data = RE.RDbyyear.Freeze , mapping = aes(x = MAJOR_AREA_CODE, y =  CPUE, fill = AVERAGE)) +  geom_bar(stat="identity", color="black", position=position_dodge()) + scale_fill_grey() + theme_classic() + labs(
  #title = "10 yr avg vs post freeze avg for RD across bays using NEW baselines",
 # x = "Major bays",
 # y = "Catch per Unit Effort (#/hectare)"
#) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


## PERCENT CHANGES
#make it wide:
RE.RD.freeze.PerChange <- spread(RE.RDbyyear.Freeze, AVERAGE, CPUE)

## Add the column to put in the percent change values
RE.RD.freeze.PerChange$first_perChange <- NA
RE.RD.freeze.PerChange$second_perChange <- NA

# for loop calculating per change for the first year
for (i in 1:nrow(RE.RD.freeze.PerChange)){
  RE.RD.freeze.PerChange$first_perChange[i] = format(((RE.RD.freeze.PerChange$`1st year`[i] - RE.RD.freeze.PerChange$`10 yrs`[i]) /RE.RD.freeze.PerChange$`10 yrs`[i]) * 100 , scientific = F)
}

#for loop for calculating per change for the 2nd year to the baseline = 
for (i in 1:nrow(RE.RD.freeze.PerChange)){
  RE.RD.freeze.PerChange$second_perChange[i] = format(((RE.RD.freeze.PerChange$`2nd year`[i] - RE.RD.freeze.PerChange$`10 yrs`[i]) /RE.RD.freeze.PerChange$`10 yrs`[i]) * 100 , scientific = F)
}


```

```{r Freeze Red Drum Table}

kable(RE.RD.freeze.PerChange, "latex", booktabs = T, caption = "Red Drum percent changes after freeze event") %>% 
  kable_styling(latex_options = "HOLD_position", full_width = F)

```

```{r Spotted Seatrout and Texas Freeze}

# Spotted seatrout freeze baseline
#I had to first subset into the 10 year frame I wanted (no averaging)
subset7 <- bag.seines %>%
  filter(YEAR > 2009 & YEAR < 2020 ) %>% 
  group_by(MAJOR_AREA_CODE)
#summarize(mean(rd_CPUE)) %>%
#rename("CPUE" = "mean(rd_CPUE)")

#Then I had to subset for only the months I wanted for spotted seatrout (june - end of dec)
subset8 <- subset7 %>% 
  filter(MONTH > 5 ) %>% 
  group_by(MAJOR_AREA_CODE)

#ggplot(subset8, mapping = aes(x=JULIAN_DATE, y = sst_CPUE)) + geom_point() + theme_classic()

#Final step = Averaging for the baseline
RE.SST10yr.freeze <- subset8 %>% 
  group_by(MAJOR_AREA_CODE) %>% 
  summarize(mean(sst_CPUE)) %>% 
  rename("CPUE" = "mean(sst_CPUE)")

RE.SST10yr.freeze$SPECIES <- "Spotted Seatrout"
RE.SST10yr.freeze$AVERAGE <- "10 yrs"

## post storm calculations = 2 post storm recruitment windows
RE.SST1yr.freeze <- bag.seines %>%
  filter(between(DATE, as.Date('2021-06-01'), as.Date('2021-12-31'))) %>% 
  group_by(MAJOR_AREA_CODE) %>%
  summarize(mean(sst_CPUE)) %>%
  rename("CPUE" = "mean(sst_CPUE)")

RE.SST1yr.freeze$SPECIES <- "Spotted Seatrout"
RE.SST1yr.freeze$AVERAGE <- "1st year"


RE.SST2nd.freeze <- bag.seines %>%
  filter(between(DATE, as.Date('2022-06-01'), as.Date('2022-12-31'))) %>% 
  group_by(MAJOR_AREA_CODE) %>%
  summarize(mean(sst_CPUE)) %>%
  rename("CPUE" = "mean(sst_CPUE)")

RE.SST2nd.freeze$SPECIES <- "Spotted Seatrout"
RE.SST2nd.freeze$AVERAGE <- "2nd year"

RE.SSTbyyear.Freeze <- rbind(RE.SST10yr.freeze,RE.SST1yr.freeze,RE.SST2nd.freeze)


#Plotting
#ggplot(data = RE.SSTbyyear.Freeze , mapping = aes(x = MAJOR_AREA_CODE, y =  CPUE, fill = AVERAGE)) +  geom_bar(stat="identity", color="black", position=position_dodge()) + scale_fill_grey() + theme_classic() + labs(
 # title = "10 yr avg vs post storm avg for SST across bays using NEW baselines",
  #x = "Major bays",
  #y = "Catch per Unit Effort (#/hectare)"
#) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


## PERCENT CHANGES
#make it wide:
RE.SST.PerChange.freeze <- spread(RE.SSTbyyear.Freeze, AVERAGE, CPUE)

## Add the column to put in the percent change values
RE.SST.PerChange.freeze$first_perChange <- NA
RE.SST.PerChange.freeze$second_perChange <- NA

# for loop calculating per change for the first year
for (i in 1:nrow(RE.SST.PerChange.freeze)){
  RE.SST.PerChange.freeze$first_perChange[i] = format(((RE.SST.PerChange.freeze$`1st year`[i] - RE.SST.PerChange.freeze$`10 yrs`[i]) /RE.SST.PerChange.freeze$`10 yrs`[i]) * 100 , scientific = F)
}

#for loop for calculating per change for the 2nd year to the baseline = 
for (i in 1:nrow(RE.SST.PerChange.freeze)){
  RE.SST.PerChange.freeze$second_perChange[i] = format(((RE.SST.PerChange.freeze$`2nd year`[i] - RE.SST.PerChange.freeze$`10 yrs`[i]) /RE.SST.PerChange.freeze$`10 yrs`[i]) * 100 , scientific = F)
}

```

```{r Freeze and Spotted Seatrout Table}
kable(RE.SST.PerChange.freeze, "latex", booktabs = T, caption = "Spotted Seatrout percent changes after freeze event") %>% 
  kable_styling(latex_options = c("HOLD_position", "scale_down"), full_width = F)

```

```{r Black Drum and Texas Freeze}

# black drum freeze baseline
#I had to first subset into the 10 year frame I wanted (no averaging)
subset11 <- bag.seines %>%
  filter(YEAR > 2009 & YEAR < 2020 ) %>% 
  group_by(MAJOR_AREA_CODE)

#Then I had to subset for only the months I wanted for black drum (April - end of oct)
subset12 <- subset11 %>% 
  filter(MONTH > 3 & MONTH < 11 ) %>% 
  group_by(MAJOR_AREA_CODE)

#ggplot(subset12, mapping = aes(x=JULIAN_DATE, y = bd_CPUE)) + geom_point() + theme_classic()

#Final step = Averaging for the baseline
RE.BD10yr.freeze <- subset12 %>% 
  group_by(MAJOR_AREA_CODE) %>% 
  summarize(mean(bd_CPUE)) %>% 
  rename("CPUE" = "mean(bd_CPUE)")

RE.BD10yr.freeze$SPECIES <- "Black Drum"
RE.BD10yr.freeze$AVERAGE <- "10 yrs"

## post storm calculations = 2 post storm recruitment windows
RE.BD1yr.freeze <- bag.seines %>%
  filter(between(DATE, as.Date('2021-04-01'), as.Date('2021-10-31'))) %>% 
  group_by(MAJOR_AREA_CODE) %>%
  summarize(mean(bd_CPUE)) %>%
  rename("CPUE" = "mean(bd_CPUE)")

RE.BD1yr.freeze$SPECIES <- "Black Drum"
RE.BD1yr.freeze$AVERAGE <- "1st year"


RE.BD2nd.freeze <- bag.seines %>%
  filter(between(DATE, as.Date('2022-04-01'), as.Date('2022-10-31'))) %>% 
  group_by(MAJOR_AREA_CODE) %>%
  summarize(mean(bd_CPUE)) %>%
  rename("CPUE" = "mean(bd_CPUE)")

RE.BD2nd.freeze$SPECIES <- "Black Drum"
RE.BD2nd.freeze$AVERAGE <- "2nd year"

RE.BDbyyear.Freeze <- rbind(RE.BD10yr.freeze,RE.BD1yr.freeze,RE.BD2nd.freeze)


#Plotting
#ggplot(data = RE.BDbyyear.Freeze , mapping = aes(x = MAJOR_AREA_CODE, y =  CPUE, fill = AVERAGE)) +  geom_bar(stat="identity", color="black", position=position_dodge()) + scale_fill_grey() + theme_classic() + labs(
 # title = "10 yr avg vs post storm avg for BD across bays using NEW baselines",
  #x = "Major bays",
  #y = "Catch per Unit Effort (#/hectare)"
#) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


## PERCENT CHANGES
#make it wide:
RE.BD.PerChange.freeze <- spread(RE.BDbyyear.Freeze, AVERAGE, CPUE)

## Add the column to put in the percent change values
RE.BD.PerChange.freeze$first_perChange <- NA
RE.BD.PerChange.freeze$second_perChange <- NA

# for loop calculating per change for the first year
for (i in 1:nrow(RE.BD.PerChange.freeze)){
  RE.BD.PerChange.freeze$first_perChange[i] = format(((RE.BD.PerChange.freeze$`1st year`[i] - RE.BD.PerChange.freeze$`10 yrs`[i]) /RE.BD.PerChange.freeze$`10 yrs`[i]) * 100 , scientific = F)
}

#for loop for calculating per change for the 2nd year to the baseline = 
for (i in 1:nrow(RE.BD.PerChange.freeze)){
  RE.BD.PerChange.freeze$second_perChange[i] = format(((RE.BD.PerChange.freeze$`2nd year`[i] - RE.BD.PerChange.freeze$`10 yrs`[i]) /RE.BD.PerChange.freeze$`10 yrs`[i]) * 100 , scientific = F)
}



```

```{r Freeze and Black Drum Table}

kable(RE.BD.PerChange.freeze, "latex", booktabs = T, caption = "Black Drum percent changes after freeze event") %>% 
  kable_styling(latex_options = c("HOLD_position","scale_down"), full_width = F)

```

```{r Southern Flounder and Texas Freeze}

# southern flounder freeze baseline
#I had to first subset into the 10 year frame I wanted (no averaging)
subset15 <- bag.seines %>%
  filter(YEAR > 2009 & YEAR < 2020 ) %>% 
  group_by(MAJOR_AREA_CODE)

#Then I had to subset for only the months I wanted for southern flounder feb -end of july
subset16 <- subset15 %>% 
  filter(MONTH > 1 & MONTH < 8 ) %>% 
  group_by(MAJOR_AREA_CODE)

#ggplot(subset16, mapping = aes(x=JULIAN_DATE, y = sf_CPUE)) + geom_point() + theme_classic()

#Final step = Averaging for the baseline
RE.SF10yr.freeze <- subset16 %>% 
  group_by(MAJOR_AREA_CODE) %>% 
  summarize(mean(sf_CPUE)) %>% 
  rename("CPUE" = "mean(sf_CPUE)")

RE.SF10yr.freeze$SPECIES <- "Southern Flounder"
RE.SF10yr.freeze$AVERAGE <- "10 yrs"

## post storm calculations = 2 post storm recruitment windows
RE.SF1yr.freeze <- bag.seines %>%
  filter(between(DATE, as.Date('2021-02-22'), as.Date('2021-07-31'))) %>% 
  group_by(MAJOR_AREA_CODE) %>%
  summarize(mean(sf_CPUE)) %>%
  rename("CPUE" = "mean(sf_CPUE)")

RE.SF1yr.freeze$SPECIES <- "Southern Flounder"
RE.SF1yr.freeze$AVERAGE <- "1st year"


RE.SF2nd.freeze <- bag.seines %>%
  filter(between(DATE, as.Date('2022-02-22'), as.Date('2022-07-31'))) %>% 
  group_by(MAJOR_AREA_CODE) %>%
  summarize(mean(sf_CPUE)) %>%
  rename("CPUE" = "mean(sf_CPUE)")

RE.SF2nd.freeze$SPECIES <- "Southern Flounder"
RE.SF2nd.freeze$AVERAGE <- "2nd year"

RE.SFbyyear.Freeze <- rbind(RE.SF10yr.freeze,RE.SF1yr.freeze,RE.SF2nd.freeze)


#Plotting
#ggplot(data = RE.SFbyyear.Freeze , mapping = aes(x = MAJOR_AREA_CODE, y =  CPUE, fill = AVERAGE)) +  geom_bar(stat="identity", color="black", position=position_dodge()) + scale_fill_grey() + theme_classic() + labs(
 # title = "10 yr avg vs post storm avg for SF across bays using NEW baselines",
  #x = "Major bays",
  #y = "Catch per Unit Effort (#/hectare)"
#) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


## PERCENT CHANGES
#make it wide:
RE.SF.PerChange.freeze <- spread(RE.SFbyyear.Freeze, AVERAGE, CPUE)

## Add the column to put in the percent change values
RE.SF.PerChange.freeze$first_perChange <- NA
RE.SF.PerChange.freeze$second_perChange <- NA

# for loop calculating per change for the first year
for (i in 1:nrow(RE.SF.PerChange.freeze)){
  RE.SF.PerChange.freeze$first_perChange[i] = format(((RE.SF.PerChange.freeze$`1st year`[i] - RE.SF.PerChange.freeze$`10 yrs`[i]) /RE.SF.PerChange.freeze$`10 yrs`[i]) * 100 , scientific = F)
}

#for loop for calculating per change for the 2nd year to the baseline = 
for (i in 1:nrow(RE.SF.PerChange.freeze)){
  RE.SF.PerChange.freeze$second_perChange[i] = format(((RE.SF.PerChange.freeze$`2nd year`[i] - RE.SF.PerChange.freeze$`10 yrs`[i]) /RE.SF.PerChange.freeze$`10 yrs`[i]) * 100 , scientific = F)
}


```

```{r Freeze and Southern Flounder Table}
kable(RE.SF.PerChange.freeze, "latex", booktabs = T, caption = "Southern Flounder percent changes after freeze event") %>% 
  kable_styling(latex_options = c("HOLD_position","scale_down"), full_width = F)

```

\newpage

## The following analysis is organized as follows 

A Generalized Mixed Model with a Negative Binomial Distribution for each species (4) in each storm (2)

Hurricane Harvey 

- Red Drum Model = model.1
- Spotted Seatrout Model = model.2
- Black Drum Model = model.3
- Southern Flounder Model = model.4


2021 Freeze Storm

- Red Drum Model = model.5
- Spotted Seatrout Model = model.6
- Black Drum Model = model.7
- Southern Flounder Model = model.8

## Hurricane Harvey Models

## Red Drum

Model: Red_drum ~ sin + cos + YEAR_OF_STUDY + classification  + (1 | MAJOR_AREA_CODE)



```{r Set up of the red drum data frame, include=FALSE}

# Select specific columns
library(dplyr)
harvey.rd <- bag.seines %>% dplyr::select(`MONTH`, `YEAR`, `MAJOR_AREA_CODE`, `SURFACE_AREA_NUM`, `Red_drum`, `rd_CPUE`) %>% #get the base columns
  filter(YEAR > 2013) #get it filters for the last 10 years 

harvey.rd$YEAR_OF_STUDY <- harvey.rd$YEAR - min(harvey.rd$YEAR) + 1 #add year of study

harvey.rd$sin <- sin(2*pi*harvey.rd$MONTH/12) #time is a circle 
harvey.rd$cos <- cos(2*pi*harvey.rd$MONTH/12) #time is a circle

#Classification column
# Initialize classification column
harvey.rd$classification <- NA

# Loop through each row
for (i in 1:nrow(harvey.rd)) {
  year <- harvey.rd$YEAR[i]
  month <- harvey.rd$MONTH[i]
  
  # Assign classifications based on conditions
  if (year >= 2014 & year <= 2017 & month <= 7) {
    harvey.rd$classification[i] <- "no storm"
  } else if (year == 2017 & month == 8) {
    harvey.rd$classification[i] <- "storm"
  } else if ((year == 2017 & month >= 9) | (year >= 2018 & year <= 2019)) {
    harvey.rd$classification[i] <- "post storm"
  } else if (year >= 2020 & year <= 2023) {
    harvey.rd$classification[i] <- "no storm"
  } 
}
# DATA FRAME DONE

```

```{r red drum model, include=FALSE}

### NEW MODEL NB AFTER DATAFRAME CORRECTION WITH CATCH ###
model.1 <- glmer.nb(
  Red_drum ~ sin + cos + YEAR_OF_STUDY + classification  + (1 | MAJOR_AREA_CODE), data = harvey.rd)

summary(model.1)


```

```{r table for red drum model}
#Table

# Extract a tidy summary
model.1_summary <- tidy(model.1, effects = "fixed")

# Function to assign asterisks based on significance levels
add_stars <- function(p) {
  ifelse(p < 0.001, "***", 
         ifelse(p < 0.01, "**", 
                ifelse(p < 0.05, "*", "")))
}

# Add a significance column with asterisks
model.1_summary <- model.1_summary %>%
  mutate(p.value = formatC(p.value, digits = 3),
         Significance = add_stars(as.numeric(p.value)))  # Add significance stars
# Rename columns for clarity
colnames(model.1_summary) <- c("Variable Type", "Covariate","Estimate", "Std.Error", "z value", "p-value", "Significance")

# Format and display the table
kbl(model.1_summary, caption = "Statistical results from a generalized linear mixed model analyzing how total Red Drum counts is influenced by month, year of study and storm classification type during Hurricane Harvey with major bay region as a random effect in a ten year period (2014-2023).", digits = 4, align = "c") %>%
  kable_styling(latex_options = c("striped", "hold_position")) %>%
  row_spec(0, bold = TRUE) # Bold column names

```


```{r model.1 residuals and model validation, include = FALSE}
#This will eventually be moved to the supplemental materials 

# Extract residuals from your model
residuals_model.1 <- residuals(model.1)

# Create the QQ plot using ggplot2
ggplot(data = data.frame(residuals_model.1), aes(sample = residuals_model.1)) +
  stat_qq() + 
  stat_qq_line() +
  theme_minimal() +
  labs(title = "QQ Plot of Residuals")



```

Year of study is significant (p-value = 0.009) with each additional year within the 10 year period, it is associated with a 2.6% decline in Red Drum counts. Classification post storm (p-value = <0.001) conditions are associated with a 32.2% increase in Red Drum counts. Classification storm (p-value = 0.877) is not significant, storm conditions do not significantly affect Red Drum counts. So Red Drum counts during the month of Hurricane Harvey are not significantly different to non-storm conditions. 


\newpage

## Spotted Seatrout

Model: Spotted_seatrout ~ sin + cos + YEAR_OF_STUDY + classification  + (1 | MAJOR_AREA_CODE)

```{r Set up of the spotted seatrout data frame, include=FALSE}
# Select specific columns
library(dplyr)
harvey.sst <- bag.seines %>% dplyr::select(`MONTH`, `YEAR`, `MAJOR_AREA_CODE`, `SURFACE_AREA_NUM`, `Spotted_seatrout`, `sst_CPUE`) %>% #get the base columns
  filter(YEAR > 2013) #get it filters for the last 10 years 

harvey.sst$YEAR_OF_STUDY <- harvey.sst$YEAR - min(harvey.sst$YEAR) + 1 #add year of study

harvey.sst$sin <- sin(2*pi*harvey.sst$MONTH/12) #time is a circle 
harvey.sst$cos <- cos(2*pi*harvey.sst$MONTH/12) #time is a circle

#Classification column
# Initialize classification column
harvey.sst$classification <- NA


# Loop through each row
for (i in 1:nrow(harvey.sst)) {
  year <- harvey.sst$YEAR[i]
  month <- harvey.sst$MONTH[i]
  
  # Assign classifications based on conditions
  if (year >= 2014 & year <= 2017 & month <= 7) {
    harvey.sst$classification[i] <- "no storm"
  } else if (year == 2017 & month == 8) {
    harvey.sst$classification[i] <- "storm"
  } else if ((year == 2017 & month >= 9) | (year >= 2018 & year <= 2019)) {
    harvey.sst$classification[i] <- "post storm"
  } else if (year >= 2020 & year <= 2023) {
    harvey.sst$classification[i] <- "no storm"
  } 
}
# DATA FRAME DONE

```

```{r spotted seatrout model, include=FALSE}

### NEW MODEL NB AFTER DATAFRAME CORRECTION WITH CATCH ###
model.2 <- glmer.nb(
  Spotted_seatrout ~ sin + cos + YEAR_OF_STUDY + classification  + (1 | MAJOR_AREA_CODE), data = harvey.sst)

summary(model.2)


```

```{r table for spotted seatrout model}
#Table

# Extract a tidy summary
model.2_summary <- tidy(model.2, effects = "fixed")


# Add a significance column with asterisks
model.2_summary <- model.2_summary %>%
  mutate(p.value = formatC(p.value, digits = 3), 
         Significance = add_stars(as.numeric(p.value)))  # Add significance stars


# Rename columns for clarity
colnames(model.2_summary) <- c("Variable Type", "Covariate","Estimate", "Std.Error", "z value", "p-value", "Significance")

# Format and display the table
kbl(model.2_summary, caption = "Statistical results from a generalized linear mixed model analyzing how total Spotted Seatrout counts is influenced by month, year of study and storm classification type during Hurricane Harvey with major bay region as a random effect in a ten year period (2014-2023).", digits = 4, align = "c") %>%
  kable_styling(latex_options = c("striped", "hold_position")) %>%
  row_spec(0, bold = TRUE) # Bold column names

```


```{r model.2 residuals and model validation, include = FALSE}
#This will eventually be moved to the supplemental materials 

# Extract residuals from your model
residuals_model.2 <- residuals(model.2)

# Create the QQ plot using ggplot2
ggplot(data = data.frame(residuals_model.2), aes(sample = residuals_model.2)) +
  stat_qq() + 
  stat_qq_line() +
  theme_minimal() +
  labs(title = "QQ Plot of Residuals")

```


Year of study shows no significant trend (p-value = 0.428) over time year to year in spotted seatrout counts. Classification post-storm are associated with a 21% decline in Spotted Seatrout counts (p-value = 0.0012) while storm designations are associated with a 74.1% decline in Spotted Seatrout counts (p-value <0.001).



\newpage

## Black Drum

Model: Black_drum ~ sin + cos + YEAR_OF_STUDY + classification  + (1 | MAJOR_AREA_CODE)

```{r Set up of the black drum data frame, include=FALSE}
# Select specific columns
library(dplyr)
harvey.bd <- bag.seines %>% dplyr::select(`MONTH`, `YEAR`, `MAJOR_AREA_CODE`, `SURFACE_AREA_NUM`, `Black_drum`, `bd_CPUE`) %>% #get the base columns
  filter(YEAR > 2013) #get it filters for the last 10 years 

harvey.bd$YEAR_OF_STUDY <- harvey.bd$YEAR - min(harvey.bd$YEAR) + 1 #add year of study

harvey.bd$sin <- sin(2*pi*harvey.bd$MONTH/12) #time is a circle 
harvey.bd$cos <- cos(2*pi*harvey.bd$MONTH/12) #time is a circle

#Classification column
# Initialize classification column
harvey.bd$classification <- NA


# Loop through each row
for (i in 1:nrow(harvey.bd)) {
  year <- harvey.bd$YEAR[i]
  month <- harvey.bd$MONTH[i]
  
  # Assign classifications based on conditions
  if (year >= 2014 & year <= 2017 & month <= 7) {
    harvey.bd$classification[i] <- "no storm"
  } else if (year == 2017 & month == 8) {
    harvey.bd$classification[i] <- "storm"
  } else if ((year == 2017 & month >= 9) | (year >= 2018 & year <= 2019)) {
    harvey.bd$classification[i] <- "post storm"
  } else if (year >= 2020 & year <= 2023) {
    harvey.bd$classification[i] <- "no storm"
  } 
}
# DATA FRAME DONE

```

```{r black drum model, include=FALSE}

### NEW MODEL NB AFTER DATAFRAME CORRECTION WITH CATCH ###
model.3 <- glmer.nb(
  Black_drum ~ sin + cos + YEAR_OF_STUDY + classification  + (1 | MAJOR_AREA_CODE), data = harvey.bd)

summary(model.3)

```

```{r table for black drum model}
#Table

# Extract a tidy summary
model.3_summary <- tidy(model.3, effects = "fixed")

# Add a significance column with asterisks
model.3_summary <- model.3_summary %>%
  mutate(p.value = formatC(p.value, digits = 3), 
         Significance = add_stars(as.numeric(p.value)))  # Add significance stars

# Rename columns for clarity
colnames(model.3_summary) <- c("Variable Type", "Covariate","Estimate", "Std.Error", "z value", "p-value","Significance")

# Format and display the table
kbl(model.3_summary, caption = "Statistical results from a generalized linear mixed model analyzing how total Black Drum counts is influenced by month, year of study and storm classification type during Hurricane Harvey with major bay region as a random effect in a ten year period (2014-2023).", digits = 4, align = "c") %>%
  kable_styling(latex_options = c("striped", "hold_position")) %>%
  row_spec(0, bold = TRUE) # Bold column names

```


```{r model.3 residuals and model validation, include = FALSE}
#This will eventually be moved to the supplemental materials 

# Extract residuals from your model
residuals_model.3 <- residuals(model.3)

# Create the QQ plot using ggplot2
ggplot(data = data.frame(residuals_model.3), aes(sample = residuals_model.3)) +
  stat_qq() + 
  stat_qq_line() +
  theme_minimal() +
  labs(title = "QQ Plot of Residuals")

```


Year of study is significant (p-value <0.001) where there is a 18.53% increase year to year over the 10 year period of Black Drum counts. Both classifications post storm and storm are not significant and therefore do not have an effect on Black Drum counts compared to non-storm. 





\newpage

## Southern Flounder 

Model: Southern_flounder ~ sin + cos + YEAR_OF_STUDY + classification  + (1 | MAJOR_AREA_CODE)

```{r Set up of the southern flounder data frame, include=FALSE}
# Select specific columns
library(dplyr)
harvey.sf <- bag.seines %>% dplyr::select(`MONTH`, `YEAR`, `MAJOR_AREA_CODE`, `SURFACE_AREA_NUM`, `Southern_flounder`, `sf_CPUE`) %>% #get the base columns
  filter(YEAR > 2013) #get it filters for the last 10 years 

harvey.sf$YEAR_OF_STUDY <- harvey.sf$YEAR - min(harvey.sf$YEAR) + 1 #add year of study

harvey.sf$sin <- sin(2*pi*harvey.sf$MONTH/12) #time is a circle 
harvey.sf$cos <- cos(2*pi*harvey.sf$MONTH/12) #time is a circle

#Classification column
# Initialize classification column
harvey.sf$classification <- NA


# Loop through each row
for (i in 1:nrow(harvey.sf)) {
  year <- harvey.sf$YEAR[i]
  month <- harvey.sf$MONTH[i]
  
  # Assign classifications based on conditions
  if (year >= 2014 & year <= 2017 & month <= 7) {
    harvey.sf$classification[i] <- "no storm"
  } else if (year == 2017 & month == 8) {
    harvey.sf$classification[i] <- "storm"
  } else if ((year == 2017 & month >= 9) | (year >= 2018 & year <= 2019)) {
    harvey.sf$classification[i] <- "post storm"
  } else if (year >= 2020 & year <= 2023) {
    harvey.sf$classification[i] <- "no storm"
  } 
}
# DATA FRAME DONE

```

```{r southern flounder model, include=FALSE}

### NEW MODEL NB AFTER DATAFRAME CORRECTION WITH CATCH ###
model.4 <- glmer.nb(
  Southern_flounder ~ sin + cos + YEAR_OF_STUDY + classification  + (1 | MAJOR_AREA_CODE), data = harvey.sf)

summary(model.4)

```

```{r table for southern flounder model}
#Table

# Extract a tidy summary
model.4_summary <- tidy(model.4, effects = "fixed")

# Add a significance column with asterisks
model.4_summary <- model.4_summary %>%
  mutate(p.value = formatC(p.value, digits = 3),  
         Significance = add_stars(as.numeric(p.value)))  # Add significance stars

# Rename columns for clarity
colnames(model.4_summary) <- c("Variable Type", "Covariate","Estimate", "Std.Error", "z value", "p-value", "Significance")

# Format and display the table
kbl(model.4_summary, caption = "Statistical results from a generalized linear mixed model analyzing how total Southern Flounder counts is influenced by month, year of study and storm classification type during Hurricane Harvey with major bay region as a random effect in a ten year period (2014-2023).", digits = 4, align = "c") %>%
  kable_styling(latex_options = c("striped", "hold_position")) %>%
  row_spec(0, bold = TRUE) # Bold column names

```


```{r model.4 residuals and model validation, include = FALSE}
#This will eventually be moved to the supplemental materials 

# Extract residuals from your model
residuals_model.4 <- residuals(model.4)

# Create the QQ plot using ggplot2
ggplot(data = data.frame(residuals_model.4), aes(sample = residuals_model.4)) +
  stat_qq() + 
  stat_qq_line() +
  theme_minimal() +
  labs(title = "QQ Plot of Residuals")

```


Year of study is significant (p-value 0.0008), indicating a small but significant 4.9% decrease in Southern Flounder counts over the 10 year period. Classification post storm is significant (p-value 0.0036), suggests that in post storm designations, Southern Flounder count is decreasing by 26.7%. Classification storm: though it does show a 67% decrease in Southern Flounder counts in the storm period, it is a non-significant effect. 




\newpage

## 2021 Freeze 


# Red Drum 

Model: Red_drum ~ sin + cos + YEAR_OF_STUDY + classification  + (1 | MAJOR_AREA_CODE)

```{r freeze red drum set up data frame, include=FALSE}

# Select specific columns
library(dplyr)
freeze.rd <- bag.seines %>% dplyr::select(`MONTH`, `YEAR`, `MAJOR_AREA_CODE`, `SURFACE_AREA_NUM`, `Red_drum`, `rd_CPUE`) %>% #get the base columns
  filter(YEAR > 2013) #get it filters for the last 10 years 

freeze.rd$YEAR_OF_STUDY <- freeze.rd$YEAR - min(freeze.rd$YEAR) + 1 #add year of study

freeze.rd$sin <- sin(2*pi*freeze.rd$MONTH/12) #time is a circle 
freeze.rd$cos <- cos(2*pi*freeze.rd$MONTH/12) #time is a circle

#Classification column
# Initialize classification column
freeze.rd$classification <- NA

# Loop through each row
for (i in 1:nrow(freeze.rd)) {
  year <- freeze.rd$YEAR[i]
  month <- freeze.rd$MONTH[i]
  
    # Assign classifications based on conditions
  if (year >= 2014 & (year < 2021 | (year == 2021 & month <= 1))) {
    freeze.rd$classification[i] <- "no storm"
  } else if (year == 2021 & month == 2) {
    freeze.rd$classification[i] <- "storm"
  } else if ((year == 2021 & month >= 3) | (year == 2022) | (year == 2023 & month <= 3)) {
    freeze.rd$classification[i] <- "post storm"
  } else if (year == 2023 & month >= 4 & month <= 6) {
    freeze.rd$classification[i] <- "no storm"
  } 
}
# DATA FRAME DONE

```

```{r freeze red drum model, include=FALSE}

### NEW MODEL NB AFTER DATAFRAME CORRECTION WITH CATCH ###
model.5 <- glmer.nb(
  Red_drum ~ sin + cos + YEAR_OF_STUDY + classification  + (1 | MAJOR_AREA_CODE), data = freeze.rd)

summary(model.5)

```

```{r table for freeze red drum model}
#Table

# Extract a tidy summary
model.5_summary <- tidy(model.5, effects = "fixed")

# Add a significance column with asterisks
model.5_summary <- model.5_summary %>%
  mutate(p.value = formatC(p.value, digits = 3), 
         Significance = add_stars(as.numeric(p.value)))  # Add significance stars

# Rename columns for clarity
colnames(model.5_summary) <- c("Variable Type", "Covariate","Estimate", "Std.Error", "z value", "p-value", "Significance")

# Format and display the table
kbl(model.5_summary, caption = "Statistical results from a generalized linear mixed model analyzing how total Red Drum counts is influenced by month, year of study and storm classification type during the 2021 Freeze with major bay region as a random effect in a ten year period (2014-2023).", digits = 4, align = "c") %>%
  kable_styling(latex_options = c("striped", "hold_position")) %>%
  row_spec(0, bold = TRUE) # Bold column names

```


```{r model.5 residuals and model validation, include = FALSE}
#This will eventually be moved to the supplemental materials 

# Extract residuals from your model
residuals_model.5 <- residuals(model.5)

# Create the QQ plot using ggplot2
ggplot(data = data.frame(residuals_model.5), aes(sample = residuals_model.5)) +
  stat_qq() + 
  stat_qq_line() +
  theme_minimal() +
  labs(title = "QQ Plot of Residuals")

```


Year of study (p-value = 0.063) is not significant effect on Red Drum counts. Classification post storm (p-value = 0.025) conditions are associated with a 16.1% decrease in Red Drum counts. Classification storm (p-value = <0.0001) designations are associated with a statistically significant 63.2% decrease of Red Drum counts.




\newpage

## Spotted Seatrout 


Model: Spotted_seatrout ~ sin + cos + YEAR_OF_STUDY + classification  + (1 | MAJOR_AREA_CODE)

```{r freeze spotted seatrout set up data frame, include=FALSE}

# Select specific columns
library(dplyr)
freeze.sst <- bag.seines %>% dplyr::select(`MONTH`, `YEAR`, `MAJOR_AREA_CODE`, `SURFACE_AREA_NUM`, `Spotted_seatrout`, `sst_CPUE`) %>% #get the base columns
  filter(YEAR > 2013) #get it filters for the last 10 years 

freeze.sst$YEAR_OF_STUDY <- freeze.sst$YEAR - min(freeze.sst$YEAR) + 1 #add year of study

freeze.sst$sin <- sin(2*pi*freeze.sst$MONTH/12) #time is a circle 
freeze.sst$cos <- cos(2*pi*freeze.sst$MONTH/12) #time is a circle

#Classification column
# Initialize classification column
freeze.sst$classification <- NA

# Loop through each row
for (i in 1:nrow(freeze.sst)) {
  year <- freeze.sst$YEAR[i]
  month <- freeze.sst$MONTH[i]
  
    # Assign classifications based on conditions
  if (year >= 2014 & (year < 2021 | (year == 2021 & month <= 1))) {
    freeze.sst$classification[i] <- "no storm"
  } else if (year == 2021 & month == 2) {
    freeze.sst$classification[i] <- "storm"
  } else if ((year == 2021 & month >= 3) | (year == 2022) | (year == 2023 & month <= 3)) {
    freeze.sst$classification[i] <- "post storm"
  } else if (year == 2023 & month >= 4 & month <= 6) {
    freeze.sst$classification[i] <- "no storm"
  } 
}
# DATA FRAME DONE

```

```{r freeze spotted seatrout model, include=FALSE}

### NEW MODEL NB AFTER DATAFRAME CORRECTION WITH CATCH ###
model.6 <- glmer.nb(
  Spotted_seatrout ~ sin + cos + YEAR_OF_STUDY + classification  + (1 | MAJOR_AREA_CODE), data = freeze.sst)

summary(model.6)



```

```{r table for freeze spotted seatrout model}
#Table

# Extract a tidy summary
model.6_summary <- tidy(model.6, effects = "fixed")

# Add a significance column with asterisks
model.6_summary <- model.6_summary %>%
  mutate(p.value = formatC(p.value, digits = 3),
         Significance = add_stars(as.numeric(p.value)))  # Add significance stars

# Rename columns for clarity
colnames(model.6_summary) <- c("Variable Type", "Covariate","Estimate", "Std.Error", "z value", "p-value", "Significance")

# Format and display the table
kbl(model.6_summary, caption = "Statistical results from a generalized linear mixed model analyzing how total Spotted Seatrout counts is influenced by month, year of study and storm classification type during the 2021 Freeze with major bay region as a random effect in a ten year period (2014-2023).", digits = 4, align = "c") %>%
  kable_styling(latex_options = c("striped", "hold_position")) %>%
  row_spec(0, bold = TRUE) # Bold column names

```


```{r model.6 residuals and model validation, include = FALSE}
#This will eventually be moved to the supplemental materials 

# Extract residuals from your model
residuals_model.6 <- residuals(model.6)

# Create the QQ plot using ggplot2
ggplot(data = data.frame(residuals_model.6), aes(sample = residuals_model.6)) +
  stat_qq() + 
  stat_qq_line() +
  theme_minimal() +
  labs(title = "QQ Plot of Residuals")

```


Year of study is not significant, suggesting no clear long-term trend of spotted seatrout count over the years in the study period. Classifications post storm and storm were found to be non-significant. post storm would be a 5.4% decrease and storm conditions a 3.4% but non-significant decreases. 


\newpage


## Black Drum

Model: Black_drum ~ sin + cos + YEAR_OF_STUDY + classification  + (1 | MAJOR_AREA_CODE)

```{r freeze black drum set up data frame, include=FALSE}

# Select specific columns
library(dplyr)
freeze.bd <- bag.seines %>% dplyr::select(`MONTH`, `YEAR`, `MAJOR_AREA_CODE`, `SURFACE_AREA_NUM`, `Black_drum`, `bd_CPUE`) %>% #get the base columns
  filter(YEAR > 2013) #get it filters for the last 10 years 

freeze.bd$YEAR_OF_STUDY <- freeze.bd$YEAR - min(freeze.bd$YEAR) + 1 #add year of study

freeze.bd$sin <- sin(2*pi*freeze.bd$MONTH/12) #time is a circle 
freeze.bd$cos <- cos(2*pi*freeze.bd$MONTH/12) #time is a circle

#Classification column
#Initialize classification column
freeze.bd$classification <- NA

# Loop through each row
for (i in 1:nrow(freeze.bd)) {
  year <- freeze.bd$YEAR[i]
  month <- freeze.bd$MONTH[i]
  
    # Assign classifications based on conditions
  if (year >= 2014 & (year < 2021 | (year == 2021 & month <= 1))) {
    freeze.bd$classification[i] <- "no storm"
  } else if ((year == 2021 & month >= 3) | (year == 2022) | (year == 2023 & month <= 3)) {
    freeze.bd$classification[i] <- "post storm"
  } else if (year == 2023 & month >= 4 & month <= 6) {
    freeze.bd$classification[i] <- "no storm"
  } 
}

#Remove February of 2021 because catch was 0 
freeze.bd <- na.omit(freeze.bd)

# DATA FRAME DONE

```

```{r freeze black drum model, include=FALSE}

### NEW MODEL NB AFTER DATAFRAME CORRECTION WITH CATCH ###
model.7 <- glmer.nb(
  Black_drum ~ sin + cos + YEAR_OF_STUDY + classification  + (1 | MAJOR_AREA_CODE), data = freeze.bd)

summary(model.7)

```

```{r table for freeze black drum model}
#Table

# Extract a tidy summary
model.7_summary <- tidy(model.7, effects = "fixed")

# Add a significance column with asterisks
model.7_summary <- model.7_summary %>%
  mutate(p.value = formatC(p.value, digits = 3),  
         Significance = add_stars(as.numeric(p.value)))  # Add significance stars

# Rename columns for clarity
colnames(model.7_summary) <- c("Variable Type", "Covariate","Estimate", "Std.Error", "z value", "p-value", "Significance")

# Format and display the table
kbl(model.7_summary, caption = "Statistical results from a generalized linear mixed model analyzing how total Black Drum counts is influenced by month, year of study and storm classification type during the 2021 Freeze with major bay region as a random effect in a ten year period (2014-2023).", digits = 4, align = "c") %>%
  kable_styling(latex_options = c("striped", "hold_position")) %>%
  row_spec(0, bold = TRUE) # Bold column names

```


```{r model.7 residuals and model validation, include = FALSE}
#This will eventually be moved to the supplemental materials 

# Extract residuals from your model
residuals_model.7 <- residuals(model.7)

# Create the QQ plot using ggplot2
ggplot(data = data.frame(residuals_model.7), aes(sample = residuals_model.7)) +
  stat_qq() + 
  stat_qq_line() +
  theme_minimal() +
  labs(title = "QQ Plot of Residuals")


```


Year of study was found to be a significant effect (p value = <0.0001) on Black Drum counts. Suggests an 11.17% increase of Black Drum counts over the course of the study period. Classification post storm has a significant effect (p value = <0.0001), during post storm classifications, Black Drum counts have 81.18% increase compared to non storm. No classification of storm as the catches were 0 for this month and year. 




\newpage

## Southern Flounder 

Model: Southern_flounder ~ sin + cos + YEAR_OF_STUDY + classification  + (1 | MAJOR_AREA_CODE)

```{r freeze southern flounder set up data frame, include=FALSE}

# Select specific columns
library(dplyr)
freeze.sf <- bag.seines %>% dplyr::select(`MONTH`, `YEAR`, `MAJOR_AREA_CODE`, `SURFACE_AREA_NUM`, `Southern_flounder`, `sf_CPUE`) %>% #get the base columns
  filter(YEAR > 2013) #get it filters for the last 10 years 

freeze.sf$YEAR_OF_STUDY <- freeze.sf$YEAR - min(freeze.sf$YEAR) + 1 #add year of study

freeze.sf$sin <- sin(2*pi*freeze.sf$MONTH/12) #time is a circle 
freeze.sf$cos <- cos(2*pi*freeze.sf$MONTH/12) #time is a circle

#Classification column
# Initialize classification column
freeze.sf$classification <- NA

# Loop through each row
for (i in 1:nrow(freeze.sf)) {
  year <- freeze.sf$YEAR[i]
  month <- freeze.sf$MONTH[i]
  
    # Assign classifications based on conditions
  if (year >= 2014 & (year < 2021 | (year == 2021 & month <= 1))) {
    freeze.sf$classification[i] <- "no storm"
  } else if ((year == 2021 & month >= 3) | (year == 2022) | (year == 2023 & month <= 3)) {
    freeze.sf$classification[i] <- "post storm"
  } else if (year == 2023 & month >= 4 & month <= 6) {
    freeze.sf$classification[i] <- "no storm"
  } 
}

#Remove February of 2021 because catch was 0 
freeze.sf <- na.omit(freeze.sf)

# DATA FRAME DONE

```

```{r freeze southern flounder model, include=FALSE}

### NEW MODEL NB AFTER DATAFRAME CORRECTION WITH CATCH ###
model.8 <- glmer.nb(
  Southern_flounder ~ sin + cos + YEAR_OF_STUDY + classification  + (1 | MAJOR_AREA_CODE), data = freeze.sf)

summary(model.8)

```

```{r table for freeze southern flounder model }
#Table

# Extract a tidy summary
model.8_summary <- tidy(model.8, effects = "fixed")

# Add a significance column with asterisks
model.8_summary <- model.8_summary %>%
  mutate(p.value = formatC(p.value, digits = 3),  
         Significance = add_stars(as.numeric(p.value)))  # Add significance stars

# Rename columns for clarity
colnames(model.8_summary) <- c("Variable Type", "Covariate","Estimate", "Std.Error", "z value", "p-value", "Significance")

# Format and display the table
kbl(model.8_summary, caption = "Statistical results from a generalized linear mixed model analyzing how total Southern Flounder counts is influenced by month, year of study and storm classification type during the 2021 Freeze with major bay region as a random effect in a ten year period (2014-2023).", digits = 4, align = "c") %>%
  kable_styling(latex_options = c("striped", "hold_position")) %>%
  row_spec(0, bold = TRUE) # Bold column names

```


```{r model.8 residuals and model validation, include = FALSE}
#This will eventually be moved to the supplemental materials 

# Extract residuals from your model
residuals_model.8 <- residuals(model.8)

# Create the QQ plot using ggplot2
ggplot(data = data.frame(residuals_model.8), aes(sample = residuals_model.7)) +
  stat_qq() + 
  stat_qq_line() +
  theme_minimal() +
  labs(title = "QQ Plot of Residuals")

```

Year of study is significant (p value = <0.001), meaning there was a 14.1% decrease/decline in southern flounder counts during the study period. Classification post storm is significant (p value = <0.0001), meaning there was a 178.1% increase. in southern flounder counts compared to non-storm. There is no storm classification as catch was 0 for this fish during the storm month.





